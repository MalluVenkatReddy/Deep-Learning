{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a02687",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the purpose of forward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385562a",
   "metadata": {},
   "source": [
    "## Forward propagation is where input data is fed through a network, in a forward direction, to generate an output. \n",
    "## The data is accepted by hidden layers and processed, as per the activation function, and moves to the successive layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cae225",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How is forward propagation implemented mathematically in a single-layer feed forward neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a7052",
   "metadata": {},
   "source": [
    "step1: initialize weights and bias randomly\n",
    "\n",
    "step2: based on the weights and bias initialized, calculate the neurons as weighted sum of (weights and inputs),\n",
    "calculate y_pred = weighted sum of neurons\n",
    "\n",
    "step3: we will calculate the loss of teh network  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd334e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How are activation functions used during forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac4fd60",
   "metadata": {},
   "source": [
    "## During forward propagation, pre-activation and activation take place at each hidden and output layer node of a neural network. The pre-activation function is the calculation of the weighted sum. The activation function is applied, based on the weighted sum, to make the neural network flow non-linearly using bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the role of weights and biases in forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83185b27",
   "metadata": {},
   "source": [
    "step1: initialize weights and bias randomly\n",
    "\n",
    "step2: based on the weights and bias initialized, calculate the neurons as weighted sum of (weights and inputs),\n",
    "calculate y_pred = weighted sum of neurons\n",
    "\n",
    "step3: we will calculate the loss of teh network  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48985fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the purpose of applying a softmax function in the output layer during forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c36fe",
   "metadata": {},
   "source": [
    "Backpropagation algorithms are used extensively to train feedforward neural networks in areas such as deep learning.\n",
    "\n",
    "They efficiently compute the gradient of the loss function with respect to the network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21310cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What is the purpose of backward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22016b05",
   "metadata": {},
   "source": [
    "## Backpropagation, short for \"backward propagation of errors,\" is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How is backward propagation mathematically calculated in a single-layer feedforward neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5561f4",
   "metadata": {},
   "source": [
    "1. in backward propagation, loss will calculate based on initilaize weigthts.\n",
    "2. To minimize loss, we needm to update weights.\n",
    "3. w(t+1)=w(t)-learning rate * Gradient descent\n",
    "\n",
    "this step will repeat until loss minimizes as per requiremnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Can you explain the concept of the chain rule and its application in backward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25663f",
   "metadata": {},
   "source": [
    "## The algorithm is used to effectively train a neural network through a method called chain rule. In simple terms, after each forward pass through a network, backpropagation performs a backward pass while adjusting the model's parameters (weights and biases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. What are some common challenges or issues that can occur during backward propagation, and how \n",
    "can they be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba3b51d",
   "metadata": {},
   "source": [
    "It is slow, all previous layers are locked until gradients for the current layer is calculated. \n",
    "\n",
    "It suffers from vanishing or exploding gradients problem. \n",
    "\n",
    "It suffers from overfitting & underfitting problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2317f8b",
   "metadata": {},
   "source": [
    "The actual performance of backpropagation on a specific problem is dependent on the input data.\n",
    "\n",
    "Back propagation algorithm in data mining can be quite sensitive to noisy data\n",
    "\n",
    "You need to use the matrix-based approach for backpropagation instead of mini-batch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
